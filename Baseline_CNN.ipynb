{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccee736-758b-4545-ac24-ff16dc6fa51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "datas = sio.loadmat('dataset_mapping.mat')\n",
    "bed_select=datas['bed_select']\n",
    "bed_whole=datas['bed_whole']\n",
    "pillow_up=datas['pillow_up']\n",
    "person = datas['person']\n",
    "posture = datas['posture']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a4f20-91af-4c65-8ca0-436626f05575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from matplotlib import pyplot\n",
    "def create_model(input_shape=(16,40,1),output_shape=(32,48,1)):\n",
    "    init = RandomNormal(stddev=0.01)\n",
    "    in_image = Input(shape=input_shape)\n",
    "    n_filters1=32\n",
    "    g1 = Conv2D(n_filters1, (4,6), strides=(1,1), kernel_initializer=init)(in_image)\n",
    "    g1 = LeakyReLU(alpha=0.2)(g1)\n",
    "    g2= Conv2D(n_filters1*2, (3,5), strides=(1,1), kernel_initializer=init)(g1)\n",
    "    g2 = LeakyReLU(alpha=0.2)(g2)\n",
    "    g3= Conv2D(n_filters1*2, (3,5), strides=(1,1), kernel_initializer=init)(g2)\n",
    "    g3 = LeakyReLU(alpha=0.2)(g3)\n",
    "    g4= Conv2D(n_filters1*2, (2,4), strides=(1,1), kernel_initializer=init)(g3)\n",
    "    g4 = LeakyReLU(alpha=0.2)(g4)\n",
    "    g4= Conv2D(n_filters1*2, (2,4), strides=(1,1), kernel_initializer=init)(g4)\n",
    "    g4 = LeakyReLU(alpha=0.2)(g4)\n",
    "    g4 = Activation('relu')(g4)\n",
    "    g5=Conv2DTranspose(n_filters1*2, (2,4), strides=(1,1), kernel_initializer=init)(g4)\n",
    "    g5 = LeakyReLU(alpha=0.2)(g5)\n",
    "    g5=Conv2DTranspose(n_filters1*2, (7,7), strides=(1,1), kernel_initializer=init)(g5)\n",
    "    g5 = LeakyReLU(alpha=0.2)(g5)\n",
    "    g6=Conv2DTranspose(n_filters1*2, (7,7), strides=(1,1), kernel_initializer=init)(g5)\n",
    "    g6 = LeakyReLU(alpha=0.2)(g6)\n",
    "    g7=Conv2DTranspose(n_filters1, (7,7), strides=(1,1), kernel_initializer=init)(g6)\n",
    "    g7 = LeakyReLU(alpha=0.2)(g7)\n",
    "    g8=Conv2DTranspose(1, (7,7), strides=(1,1), kernel_initializer=init)(g7)\n",
    "    g8 = LeakyReLU(alpha=0.2)(g8)\n",
    "    out_image = Activation('relu')(g8)\n",
    "    model = Model(in_image, out_image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a587e-31c3-41f9-bbd1-e9da530c4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "#for i in range(16):\n",
    "i=15\n",
    "ood_idx = np.where(posture==i)[0]\n",
    "indis_idx = np.setdiff1d(np.arange(len(posture)), ood_idx)\n",
    "indis_input = bed_select[indis_idx,:,:]\n",
    "ood_input = bed_select[ood_idx,:,:]\n",
    "indis_output = pillow_up[indis_idx,:,:]\n",
    "ood_output = pillow_up[ood_idx,:,:]\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(indis_input, indis_output,train_size=0.9)\n",
    "scaler = MinMaxScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "reshaped_xtr = X_tr.reshape(X_tr.shape[0],-1)\n",
    "reshaped_xte = X_te.reshape(X_te.shape[0],-1)\n",
    "reshaped_ytr = y_tr.reshape(y_tr.shape[0],-1)\n",
    "reshaped_yte = y_te.reshape(y_te.shape[0],-1)\n",
    "reshaped_xood = ood_input.reshape(ood_input.shape[0],-1)\n",
    "reshaped_yood = ood_output.reshape(ood_output.shape[0],-1)\n",
    "\n",
    "normalized_xtr1 = scaler.fit_transform(reshaped_xtr)\n",
    "normalized_xte1 = scaler.transform(reshaped_xte)\n",
    "normalized_xood1 = scaler.transform(reshaped_xood)\n",
    "normalized_ytr1 = scaler2.fit_transform(reshaped_ytr)\n",
    "normalized_yte1 = scaler2.transform(reshaped_yte)\n",
    "normalized_yood1 = scaler2.transform(reshaped_yood)\n",
    "\n",
    "normalized_xtr = normalized_xtr1.reshape(X_tr.shape)\n",
    "normalized_xte = normalized_xte1.reshape(X_te.shape)\n",
    "normalized_ytr = normalized_ytr1.reshape(y_tr.shape)\n",
    "normalized_yte = normalized_yte1.reshape(y_te.shape)\n",
    "normalized_xood = normalized_xood1.reshape(ood_input.shape)\n",
    "normalized_yood = normalized_yood1.reshape(ood_output.shape)\n",
    "\n",
    "input_shape = (16,40,1)\n",
    "output_shape = (32,48,1)\n",
    "normalized_xtr = normalized_xtr[:,:,:,np.newaxis]\n",
    "normalized_xte = normalized_xte[:,:,:,np.newaxis]\n",
    "normalized_ytr = normalized_ytr[:,:,:,np.newaxis]\n",
    "normalized_yte = normalized_yte[:,:,:,np.newaxis]\n",
    "normalized_xood = normalized_xood[:,:,:,np.newaxis]\n",
    "normalized_yood = normalized_yood[:,:,:,np.newaxis]\n",
    "model = create_model(input_shape, output_shape)\n",
    "lr = 0.1\n",
    "batch_size = 64\n",
    "train_epoch = 128\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "modelname = 'best_model_baseline_' + str(i) + '.h5'\n",
    "checkpoint = ModelCheckpoint(modelname, monitor='val_loss', mode='min', save_best_only=True, verbose=1)\n",
    "\n",
    "history = model.fit(normalized_xtr,normalized_ytr,batch_size=batch_size, epochs=150,validation_data=(normalized_xte,normalized_yte), callbacks=[checkpoint])\n",
    "import keras\n",
    "model = keras.models.load_model(modelname)\n",
    "y_pred_norm=model.predict(normalized_xte)\n",
    "reshaped_ypred = y_pred_norm.reshape(y_pred_norm.shape[0],-1)\n",
    "y_pred1 = scaler2.inverse_transform(reshaped_ypred)\n",
    "y_pred = y_pred1.reshape(y_pred_norm.shape)\n",
    "y_te = y_te[:,:,:,np.newaxis]\n",
    "print(np.mean(np.abs(y_pred-y_te)))\n",
    "\n",
    "ood_output = ood_output[:,:,:,np.newaxis]\n",
    "y_pred_norm_ood=model.predict(normalized_xood)\n",
    "reshaped_ypred_ood = y_pred_norm_ood.reshape(y_pred_norm_ood.shape[0],-1)\n",
    "y_pred_ood1 = scaler2.inverse_transform(reshaped_ypred_ood)\n",
    "y_pred_ood = y_pred_ood1.reshape(ood_output.shape)\n",
    "\n",
    "print(np.mean(np.abs(y_pred_ood-ood_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf3cf26-c405-4123-93dd-fc9376699d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_pred[0,:,:,0]\n",
    "b = y_te[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d7b0d-a140-413e-855d-d991c48c5a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample matrix\n",
    "matrix = a\n",
    "\n",
    "# Plot the colormap of the matrix\n",
    "plt.imshow(matrix, cmap='viridis')\n",
    "#plt.colorbar()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "matrix = b\n",
    "\n",
    "# Plot the colormap of the matrix\n",
    "plt.imshow(matrix, cmap='viridis')\n",
    "#plt.colorbar()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35963f75-08e0-4620-88f6-357f21fae16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c= y_pred_ood[3,:,:,0]\n",
    "d = ood_output[3,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96159a03-2763-43ce-9cf2-77e7b93895b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = c\n",
    "\n",
    "# Plot the colormap of the matrix\n",
    "plt.imshow(matrix, cmap='viridis')\n",
    "#plt.colorbar()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "matrix = d\n",
    "\n",
    "# Plot the colormap of the matrix\n",
    "plt.imshow(matrix, cmap='viridis')\n",
    "#plt.colorbar()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64083bdb-bfd6-4767-bcef-ac60d6e0284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max = np.max(y_te.reshape(len(y_te),-1),axis = 1)\n",
    "percent_err = np.mean(np.abs(y_pred-y_te)/y_max[:,np.newaxis,np.newaxis,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e2e4f-def5-4c7f-acdc-f99f19576865",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e348a-3903-40c8-8c3f-6e020ef39b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_max = np.max(ood_output.reshape(len(ood_output),-1),axis = 1)\n",
    "percent_err = np.mean(np.abs(y_pred_ood-ood_output)/y_max[:,np.newaxis,np.newaxis,np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700fd9d6-f65a-4a49-8f1c-b5531ba66bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
